{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff7d5676",
   "metadata": {},
   "source": [
    "## Read first name statistics (from DVV) from excel file to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239c3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "xls = pd.ExcelFile('DVV/etunimitilasto-2022-02-07-dvv.xlsx')\n",
    "# file includes sheets for statistics on all names and first names\n",
    "# using statistics on first names only\n",
    "female_all = pd.read_excel(xls, 'Naiset ens')\n",
    "male_all = pd.read_excel(xls, 'Miehet ens')\n",
    "\n",
    "female_all.to_csv ('DVV/female_names.csv', index = None, header=True)\n",
    "male_all.to_csv ('DVV/male_names.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df9ed0",
   "metadata": {},
   "source": [
    "## Parse raw first name lists \n",
    "ie remove all extra characters suchs as white spaces, html tags etc. (result of copying data from sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073412c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def parse_wiki_name_list(source_file, target_file):\n",
    "    with open(source_file, 'r') as source, open(target_file, 'a') as target:\n",
    "        for line in source:\n",
    "            # ignore empty lines and titles indicating starting letter of name\n",
    "            if len(line.strip()) > 1:\n",
    "                target.write(line.strip() + '\\n')\n",
    "\n",
    "def remove_html(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "def parse_html_name_list(source_file, target_file):\n",
    "    with open(source_file, 'r') as source, open(target_file, 'a') as target:\n",
    "        for line in source:\n",
    "            # ignore empty lines and 'continuation' tags\n",
    "            if len(line) > 1 and not 'cont.' in line:\n",
    "                line = remove_html(line).strip()\n",
    "                # some names in the list are gender neutral - they are marked as f/m in the corresponding lists\n",
    "                # remove the f/m marking\n",
    "                if line.endswith(\" f\") or line.endswith(\" m\"):\n",
    "                    line = line[:len(line)-2]\n",
    "                target.write(line + '\\n')\n",
    "\n",
    "# parse name lists compiled from multiple sources\n",
    "def parse_random_name_list(source_file, target_file):\n",
    "    with open(source_file, 'r') as source, open(target_file, 'a') as target:\n",
    "        for line in source:\n",
    "            # ignore empty lines and comments\n",
    "            if len(line.strip()) > 1 and not line.startswith(\"#\"):\n",
    "                line = remove_extra(line).strip()\n",
    "                # get rid of last names, titles etc\n",
    "                # note: this is done with the assumption of there being no two part names\n",
    "                line = line.split()[0]\n",
    "                target.write(line + '\\n')\n",
    "\n",
    "# remove all extra tags, punctuation etc (from copying from wikipedia)\n",
    "def remove_extra(text):\n",
    "    clean = re.compile('\\[.*?\\]')\n",
    "    return re.sub(clean, '', text).translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d349bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_wiki_name_list(\"Raw/fswe_female_names_raw.txt\", \"Parsed/fswe_female_names.txt\")\n",
    "parse_wiki_name_list(\"Raw/fswe_male_names_raw.txt\", \"Parsed/fswe_male_names.txt\")\n",
    "parse_wiki_name_list(\"Raw/fin_female_names_raw.txt\", \"Parsed/fin_female_names.txt\")\n",
    "parse_wiki_name_list(\"Raw/fin_male_names_raw.txt\", \"Parsed/fin_male_names.txt\")\n",
    "\n",
    "parse_html_name_list(\"Raw/sami_female_names_raw.txt\", \"Parsed/sami_female_names.txt\")\n",
    "parse_html_name_list(\"Raw/sami_male_names_raw.txt\", \"Parsed/sami_male_names.txt\")\n",
    "parse_html_name_list(\"Raw/rus_female_names_raw.txt\", \"Parsed/rus_female_names.txt\")\n",
    "parse_html_name_list(\"Raw/rus_male_names_raw.txt\", \"Parsed/rus_male_names.txt\")\n",
    "\n",
    "parse_random_name_list(\"Raw/roma_male_names_raw.txt\", \"Parsed/roma_male_names.txt\")\n",
    "parse_random_name_list(\"Raw/roma_female_names_raw.txt\", \"Parsed/roma_female_names.txt\")\n",
    "parse_random_name_list(\"Raw/som_male_names_raw.txt\", \"Parsed/som_male_names.txt\")\n",
    "parse_random_name_list(\"Raw/som_female_names_raw.txt\", \"Parsed/som_female_names.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103c50c6",
   "metadata": {},
   "source": [
    "## Get top n names from each name list\n",
    "\n",
    "Using DVV statistics on name counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b493fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for normalizing Sami names\n",
    "from unidecode import unidecode\n",
    "\n",
    "def normalize_name(name):\n",
    "    return unidecode(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b886ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_all_names(file):\n",
    "    result = {}\n",
    "    with open(file) as all_f:\n",
    "        reader = csv.DictReader(all_f)\n",
    "        result = {row['Etunimi']:row['Lukumäärä'] for row in reader}\n",
    "    return result\n",
    "\n",
    "all_female_names = get_all_names(\"DVV/female_names.csv\")\n",
    "all_male_names = get_all_names(\"DVV/male_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b60e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_names = None \n",
    "\n",
    "def get_top_n_names(eth_names, all_names, n=10, normalize=False):\n",
    "    with open(eth_names) as eth:\n",
    "        # TODO handle normalization for Sami names\n",
    "        all_found_names = [name.strip() for name in eth if name.strip() in all_names.keys()]\n",
    "        # remove names that occur in finnish top names\n",
    "        if fin_names:\n",
    "            all_found_names = list(set(all_found_names).difference(set(fin_names)))\n",
    "    # sort names by count and select top n\n",
    "    all_found_names.sort(key=lambda x: int(all_names[x]), reverse=True)\n",
    "    # save to file\n",
    "    top_file = f'Top/{eth_names.split(\"/\")[1]}'\n",
    "    with open(top_file, 'w') as top:\n",
    "        for name in all_found_names[:n]:\n",
    "            top.write(name + '\\n')\n",
    "    return all_found_names[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83de3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO handle special characters eg in Sami names (Suomessa nuo merkit ei virallisessa käytössä?)\n",
    "n = 10\n",
    "# get finnish names first to exclude them from other name lists\n",
    "top_fin_female_names = get_top_n_names(\"Parsed/fin_female_names.txt\", all_female_names, n)\n",
    "top_fin_male_names = get_top_n_names(\"Parsed/fin_male_names.txt\", all_male_names, n)\n",
    "fin_names = top_fin_female_names + top_fin_male_names\n",
    "\n",
    "# female names\n",
    "top_fswe_female_names = get_top_n_names(\"Parsed/fswe_female_names.txt\", all_female_names, n)\n",
    "top_sami_female_names = get_top_n_names(\"Parsed/sami_female_names.txt\", all_female_names, n, normalize=True)\n",
    "top_rus_female_names = get_top_n_names(\"Parsed/rus_female_names.txt\", all_female_names, n)\n",
    "top_roma_female_names = get_top_n_names(\"Parsed/roma_female_names.txt\", all_female_names, n)\n",
    "top_som_female_names = get_top_n_names(\"Parsed/som_female_names.txt\", all_female_names, n)\n",
    "\n",
    "# male names\n",
    "top_fswe_male_names = get_top_n_names(\"Parsed/fswe_male_names.txt\", all_male_names, n)\n",
    "top_sami_male_names = get_top_n_names(\"Parsed/sami_male_names.txt\", all_male_names, n, normalize=True)\n",
    "top_rus_male_names = get_top_n_names(\"Parsed/rus_male_names.txt\", all_male_names, n)\n",
    "top_roma_male_names = get_top_n_names(\"Parsed/roma_male_names.txt\", all_male_names, n)\n",
    "top_som_male_names = get_top_n_names(\"Parsed/som_male_names.txt\", all_male_names, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4595719c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fin': {'female': ['Tuula',\n",
       "   'Anne',\n",
       "   'Päivi',\n",
       "   'Anna',\n",
       "   'Ritva',\n",
       "   'Leena',\n",
       "   'Pirjo',\n",
       "   'Sari',\n",
       "   'Minna',\n",
       "   'Marja'],\n",
       "  'male': ['Juha',\n",
       "   'Timo',\n",
       "   'Matti',\n",
       "   'Kari',\n",
       "   'Mikko',\n",
       "   'Jari',\n",
       "   'Antti',\n",
       "   'Jukka',\n",
       "   'Mika',\n",
       "   'Markku']},\n",
       " 'swe': {'female': ['Laura',\n",
       "   'Aino',\n",
       "   'Heidi',\n",
       "   'Hanna',\n",
       "   'Sanna',\n",
       "   'Maria',\n",
       "   'Anja',\n",
       "   'Johanna',\n",
       "   'Paula',\n",
       "   'Ulla'],\n",
       "  'male': ['Janne',\n",
       "   'Ville',\n",
       "   'Markus',\n",
       "   'Leo',\n",
       "   'Kalle',\n",
       "   'Elias',\n",
       "   'Jesse',\n",
       "   'Mikael',\n",
       "   'Joel',\n",
       "   'Lasse']},\n",
       " 'sami': {'female': ['Heidi', 'Elen'],\n",
       "  'male': ['Ville',\n",
       "   'Juho',\n",
       "   'Elias',\n",
       "   'Joel',\n",
       "   'Otto',\n",
       "   'Hugo',\n",
       "   'Jonne',\n",
       "   'Viktor']},\n",
       " 'rus': {'female': ['Nina', 'Sonja', 'Marianne', 'Eva', 'Irina', 'Marina'],\n",
       "  'male': ['Marko',\n",
       "   'Aleksi',\n",
       "   'Anton',\n",
       "   'Stefan',\n",
       "   'Viktor',\n",
       "   'Andrei',\n",
       "   'Nikolai']},\n",
       " 'roma': {'female': ['Maria', 'Elli', 'Anneli', 'Rauha', 'Hilja'],\n",
       "  'male': ['Janne',\n",
       "   'Markus',\n",
       "   'Kalle',\n",
       "   'Otto',\n",
       "   'Valtteri',\n",
       "   'Roope',\n",
       "   'Santeri',\n",
       "   'Veijo',\n",
       "   'Taisto',\n",
       "   'Henry']},\n",
       " 'afro': {'female': ['Isra'], 'male': ['Mohamed', 'Abdullah']},\n",
       " 'fswe': {'female': ['Laura',\n",
       "   'Aino',\n",
       "   'Heidi',\n",
       "   'Hanna',\n",
       "   'Sanna',\n",
       "   'Maria',\n",
       "   'Anja',\n",
       "   'Johanna',\n",
       "   'Paula',\n",
       "   'Ulla'],\n",
       "  'male': ['Janne',\n",
       "   'Ville',\n",
       "   'Markus',\n",
       "   'Leo',\n",
       "   'Kalle',\n",
       "   'Elias',\n",
       "   'Jesse',\n",
       "   'Mikael',\n",
       "   'Joel',\n",
       "   'Lasse']},\n",
       " 'som': {'female': ['Isra'], 'male': ['Mohamed', 'Abdullah']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dict for creating context sentences on top n names (additional to nationality adjectives)\n",
    "import os\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# import tokenizer to check for out of vocab names\n",
    "tokenizer = BertTokenizer.from_pretrained('TurkuNLP/bert-base-finnish-cased-v1')\n",
    "\n",
    "def extract_ethnicity_gender(filename):\n",
    "    eth_end_i = filename.find('_')\n",
    "    ethnicity = filename[:eth_end_i]\n",
    "    file_no_eth = filename[eth_end_i+1:]\n",
    "    gen_end_i = file_no_eth.find('_')\n",
    "    gender = file_no_eth[:gen_end_i]\n",
    "    return ethnicity, gender\n",
    "\n",
    "result = {}\n",
    "\n",
    "for filename in os.listdir(\"Top\"):\n",
    "    filepath = os.path.join(\"Top\", filename)\n",
    "    # keep track of current ethnicity and gender\n",
    "    ethnicity, gender = extract_ethnicity_gender(filename)\n",
    "\n",
    "    if ethnicity not in result:\n",
    "        result[ethnicity] = {}\n",
    "        \n",
    "    with open(filepath) as names_f:\n",
    "        result[ethnicity][gender] = [name.strip() for name in names_f\n",
    "                                    if tokenizer.convert_tokens_to_ids(name.strip()) != 101]\n",
    "            \n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d129f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
