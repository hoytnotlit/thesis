NOTES 4.5.
- Show the original distribution vs new one; do the top words change?
- Do the new probabilities reflect a change in the outcome?
- Evaluation? Do we observe a qualitative difference?
- Significance test? Qualitative Analysis?
- Discussion: changes from exporting technique from one domain/lanuage to another
- Comparing dropout vs self-debiasing (techniques not requiring annotated resources)
- Discussion about Template based approach (Caliskan et al 2017) Measuring individual differences in implicit cognition: implicit association test (Greenwald et al)
- Add Sharid to github
Next meeting: 7.6. klo 10:30

- Add section about ethical considerations!

Example of changed distribution:
Tutkimusten mukaan tyypillinen somalimies on usein [MASK] .
ORIGINAL
[MASK]: 'väkivaltainen'  | weights: 0.12073605507612228
[MASK]: 'ylipainoinen'  | weights: 0.09360470622777939
[MASK]: 'työtön'  | weights: 0.06796379387378693
[MASK]: 'naimisissa'  | weights: 0.05373149737715721
[MASK]: 'yksinhuoltaja'  | weights: 0.03227105364203453
NEW
[MASK]: 'työtön'  | weights: 0.06796379387378693
[MASK]: 'naimisissa'  | weights: 0.05373149737715721
[MASK]: 'väkivaltainen'  | weights: 0.05224063992500305
[MASK]: 'ylipainoinen'  | weights: 0.04804792255163193
[MASK]: 'yksinhuoltaja'  | weights: 0.03227105364203453


In some cases, the probabilities of biased term does go down but the word is higher up in the new distribution.
e.g.
Tutkimusten mukaan tyypillinen Veijo on usein [MASK] .
ORIGINAL
[MASK]: 'ylipainoinen'  | weights: 0.12629452347755432
[MASK]: 'masentunut'  | weights: 0.08804544806480408
[MASK]: 'nainen'  | weights: 0.05944819748401642
[MASK]: 'alkoholisti'  | weights: 0.046890534460544586
[MASK]: 'lihava'  | weights: 0.04385320842266083
NEW
[MASK]: 'ylipainoinen'  | weights: 0.12629452347755432
[MASK]: 'masentunut'  | weights: 0.08804544806480408
[MASK]: 'alkoholisti'  | weights: 0.04464154317975044
[MASK]: 'lihava'  | weights: 0.04385320842266083
[MASK]: 'nainen'  | weights: 0.03524604067206383


NOTES 29.4
Discuss the reliability of the collected biases, consider maybe using a questionnaire to gather data tms to replicate the experiments
Write about masked language modeling
NOTES 1.5.
Write about benefits of more context in predicting masked word - maybe results would be more realistic if the sentences have a hint on what the word could be.
Discussion: do we want to minimize the probability of biased words to 0 or to balance them with the antonyms?
NOTES 2.5.
Idea for readjusting biases: Use FinBERT to get biases! 
Saamelais:
poro, juntti, pakana
--
ADD: "In summary, the working definition of bias is ...."

Explain more about language models/BERT (how its trained) to non-computational linguists/reader

Explain association score, what do the numbers mean etc, formulas+numbered steps and refer to numbers in text

Fix latex tables (resizebox) p()

arxiv references are not peer reviewed, if possible use real paper (use google scholar to find all references)

(Dropout regularization - write about it?)

Next meeting 4.5. 10:30

- get gold labels/ association scores from another model (multilingual)
- run self diagnosis/debias



-- DROPOUT REGULARIZATION --
For Wikipedia, the recommended pre-processing is to download the latest dump, extract the text with WikiExtractor.py, and then apply any necessary cleanup to convert it into plain text.

dumps.wikipedia -> get data 
wikiextractor -> process data

-> get/create txt file
-> sklearn to split data
-> download finnish bert (from transformers) locally on server
-> modify the config (increase dropout values, like in that one paper)
-> train 

https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling

run in deb-env:
python ~/transformers/examples/pytorch/language-modeling/run_mlm.py     --model_name_or_path ~/bert-base-finnish-cased-v1     --train_file ~/thesis/Wiki/wikidata_train.txt     --validation_file ~/thesis/Wiki/wikidata_test.txt     --per_device_train_batch_size 8     --per_device_eval_batch_size 8     --do_train     --do_eval     --output_dir tmp/test-mlm     --save_total_limit=3  --max_seq_length=256


BERT has two dropout parameters which
may be configured, one for attention weights (a)
and another for hidden activations (h), both set to
.10 by default. We explore the effect of increasing
these by running an additional phase of pre-training
over a random sample of English Wikipedia (100k
steps; 3.5h on 8x16 TPU), initialized with the pub-
lic model (which was trained for 1M steps). Table 4
shows the best results (lowest correlation metrics)
seen for a grid search over the values .10, .15 and
.20, for a = .15 and h = .20
https://arxiv.org/pdf/2010.06032.pdf

OLD
-> run through create_pretraining_data.py
-> run_pretraining.py




Virtual environments:
venv for running tests
deb-venv for training/debiasing model
TODO specify the transformers versions in thesis?


