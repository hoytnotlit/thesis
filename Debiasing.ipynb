{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a8c59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussuvmi@GU.GU.SE/venv/lib64/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import visualize\n",
    "import os\n",
    "import context as c, score\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = score.get_tokenizer()\n",
    "dro_tokenizer = score.get_tokenizer(\"test-mlm/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42b64fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_name):\n",
    "    with open(f\"Results/raw/{file_name}\", \"r\") as f:\n",
    "        res = json.load(f)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178aa0ac",
   "metadata": {},
   "source": [
    "## SELF-DEBIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35fd65e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_debiased = load(\"sdb_short.json\")\n",
    "l_debiased = load(\"sdb_long.json\")\n",
    "s_antonym = load(\"ant_short_probs.json\")\n",
    "l_antonym = load(\"ant_long_probs.json\")\n",
    "\n",
    "s_raw = visualize.get_sdb_df(s_debiased, c.context_t_i, tokenizer)\n",
    "s_ant_raw = visualize.get_ant_prob_df(s_antonym, c.context_t_i)\n",
    "l_raw = visualize.get_sdb_df(l_debiased, c.context_long_t_i, tokenizer)\n",
    "l_ant_raw = visualize.get_ant_prob_df(l_antonym, c.context_long_t_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d08ef531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:331: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(res.to_latex(index=False))#TODO, float_format=\"%.5f\"))\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:331: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(res.to_latex(index=False))#TODO, float_format=\"%.5f\"))\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:340: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res['Change'] = res['Change'].map('{0:.2f} %'.format)\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:41: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(result.to_latex(index=index, longtable=longtable, float_format=float_format))\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:340: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res['Change'] = res['Change'].map('{0:.2f} %'.format)\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:41: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(result.to_latex(index=index, longtable=longtable, float_format=float_format))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Biased term</th>\n",
       "      <th>Original prob.</th>\n",
       "      <th>New prob</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Finnish-Swedish</td>\n",
       "      <td>Laura</td>\n",
       "      <td>hetero (straight)</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>1.98 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Finnish-Swedish</td>\n",
       "      <td>Joel</td>\n",
       "      <td>hetero (straight)</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>1.59 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Finnish-Swedish</td>\n",
       "      <td>Laura</td>\n",
       "      <td>köyhä (poor)</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.74 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Finnish-Swedish</td>\n",
       "      <td>Joel</td>\n",
       "      <td>köyhä (poor)</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.61 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Roma</td>\n",
       "      <td>Anneli</td>\n",
       "      <td>töissä (employed)</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.37 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Roma</td>\n",
       "      <td>man</td>\n",
       "      <td>töissä (employed)</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.29 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Roma</td>\n",
       "      <td>person</td>\n",
       "      <td>töissä (employed)</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.26 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Roma</td>\n",
       "      <td>woman</td>\n",
       "      <td>töissä (employed)</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.25 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Russian</td>\n",
       "      <td>Irina</td>\n",
       "      <td>töissä (employed)</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.24 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Finnish-Swedish</td>\n",
       "      <td>man</td>\n",
       "      <td>hetero (straight)</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.21 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ethnicity  Entity        Biased term  Original prob.  New prob  \\\n",
       "38   Finnish-Swedish   Laura  hetero (straight)        0.000573  0.000561   \n",
       "48   Finnish-Swedish    Joel  hetero (straight)        0.000666  0.000655   \n",
       "30   Finnish-Swedish   Laura       köyhä (poor)        0.000499  0.000495   \n",
       "40   Finnish-Swedish    Joel       köyhä (poor)        0.000449  0.000447   \n",
       "80              Roma  Anneli  töissä (employed)        0.000120  0.000119   \n",
       "60              Roma     man  töissä (employed)        0.000040  0.000040   \n",
       "70              Roma  person  töissä (employed)        0.000049  0.000049   \n",
       "50              Roma   woman  töissä (employed)        0.000055  0.000055   \n",
       "231          Russian   Irina  töissä (employed)        0.000075  0.000075   \n",
       "18   Finnish-Swedish     man  hetero (straight)        0.000042  0.000042   \n",
       "\n",
       "     Change  \n",
       "38   1.98 %  \n",
       "48   1.59 %  \n",
       "30   0.74 %  \n",
       "40   0.61 %  \n",
       "80   0.37 %  \n",
       "60   0.29 %  \n",
       "70   0.26 %  \n",
       "50   0.25 %  \n",
       "231  0.24 %  \n",
       "18   0.21 %  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine with antonyms\n",
    "s_ant_comb = visualize.get_sdb_ant_df(s_raw, s_ant_raw)\n",
    "l_ant_comb = visualize.get_sdb_ant_df(l_raw, l_ant_raw)\n",
    "\n",
    "visualize.get_sdb_means(s_ant_comb, 'sdb_short_means.tex')\n",
    "x = visualize.get_sdb_means(l_ant_comb, 'sdb_long_means.tex')\n",
    "\n",
    "# get top n changes - biased terms\n",
    "visualize.get_top_n_changes(s_raw, file_name='sdb_s_top_10.tex', no_unk=True)\n",
    "visualize.get_top_n_changes(l_raw, file_name='sdb_l_top_10.tex', no_unk=True)\n",
    "\n",
    "# get top n changes - antonyms\n",
    "s_a_r = visualize.get_sdb_df(s_antonym, c.context_t_i, tokenizer)\n",
    "l_a_r = visualize.get_sdb_df(l_antonym, c.context_long_t_i, tokenizer)\n",
    "visualize.get_top_n_changes(s_a_r, file_name='sdb_s_ant_top_10.tex', no_unk=True)\n",
    "visualize.get_top_n_changes(l_a_r, file_name='sdb_l_ant_top_10.tex', no_unk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c960a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "167\n",
      "2\n",
      "248\n"
     ]
    }
   ],
   "source": [
    "print(len(s_ant_comb.loc[s_ant_comb['Difference'] <= 0])) # 87 rows with 0 difference\n",
    "print(len(s_ant_comb.loc[s_ant_comb['Difference'] > 0])) # 163 rows with some difference\n",
    "print(len(l_ant_comb.loc[l_ant_comb['Difference'] <= 0])) # 30 rows with 0 difference\n",
    "print(len(l_ant_comb.loc[l_ant_comb['Difference'] > 0])) # 220 rows with some difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b293d7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:41: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(result.to_latex(index=index, longtable=longtable, float_format=float_format))\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:41: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(result.to_latex(index=index, longtable=longtable, float_format=float_format))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original prob.</th>\n",
       "      <th>New prob</th>\n",
       "      <th>Antonym probability</th>\n",
       "      <th>Original difference</th>\n",
       "      <th>New difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethnicity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Finnish-Swedish</th>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roma</th>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russian</th>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sami</th>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Somali</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Original prob.  New prob  Antonym probability  \\\n",
       "Ethnicity                                                        \n",
       "Finnish-Swedish        0.000368  0.000314             0.000088   \n",
       "Roma                   0.000112  0.000109             0.000023   \n",
       "Russian                0.000145  0.000142             0.000032   \n",
       "Sami                   0.000296  0.000283             0.000200   \n",
       "Somali                 0.000017  0.000017             0.000015   \n",
       "\n",
       "                 Original difference  New difference  \n",
       "Ethnicity                                             \n",
       "Finnish-Swedish             0.000280        0.000226  \n",
       "Roma                        0.000089        0.000086  \n",
       "Russian                     0.000113        0.000110  \n",
       "Sami                        0.000096        0.000083  \n",
       "Somali                      0.000001        0.000001  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize.get_sdb_ant_diff(s_ant_comb, \"sdb_s_ant_diff.tex\")\n",
    "visualize.get_sdb_ant_diff(l_ant_comb, \"sdb_l_ant_diff.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0538dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing top k words\n",
    "sdb_top_k_s = visualize.get_top_k_df(s_debiased, tokenizer, c.context_t_i, \"new\", \"s\")\n",
    "sdb_top_k_l = visualize.get_top_k_df(l_debiased, tokenizer, c.context_long_t_i, \"new\", \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fafabdc",
   "metadata": {},
   "source": [
    "## DROPOUT REGULARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b678efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout\n",
    "dro_s_debiased = load(\"dro_short.json\")\n",
    "dro_l_debiased = load(\"dro_long.json\")\n",
    "dro_s_ant = load(\"dro_short_ant.json\")\n",
    "dro_l_ant = load(\"dro_long_ant.json\")\n",
    "\n",
    "dro_s_raw = visualize.get_sdb_df(dro_s_debiased, c.context_t_i, dro_tokenizer)\n",
    "dro_l_raw = visualize.get_sdb_df(dro_l_debiased, c.context_long_t_i, dro_tokenizer)\n",
    "dro_s_ant_raw = visualize.get_ant_prob_df(dro_s_ant, c.context_t_i)\n",
    "dro_l_ant_raw = visualize.get_ant_prob_df(dro_l_ant, c.context_long_t_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da1d810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:340: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res['Change'] = res['Change'].map('{0:.2f} %'.format)\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:41: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(result.to_latex(index=index, longtable=longtable, float_format=float_format))\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:340: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res['Change'] = res['Change'].map('{0:.2f} %'.format)\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:41: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(result.to_latex(index=index, longtable=longtable, float_format=float_format))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Biased term</th>\n",
       "      <th>Original prob.</th>\n",
       "      <th>New prob</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Russian</td>\n",
       "      <td>Irina</td>\n",
       "      <td>ahkera (diligent)</td>\n",
       "      <td>2.922330e-06</td>\n",
       "      <td>9.866292e-08</td>\n",
       "      <td>96.62 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Sami</td>\n",
       "      <td>Hugo</td>\n",
       "      <td>vaalea (light)</td>\n",
       "      <td>6.740463e-04</td>\n",
       "      <td>2.470922e-05</td>\n",
       "      <td>96.33 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Roma</td>\n",
       "      <td>Veijo</td>\n",
       "      <td>ahkera (diligent)</td>\n",
       "      <td>4.512612e-06</td>\n",
       "      <td>1.846974e-07</td>\n",
       "      <td>95.91 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Roma</td>\n",
       "      <td>Veijo</td>\n",
       "      <td>rehellinen (honest)</td>\n",
       "      <td>1.040887e-05</td>\n",
       "      <td>4.740756e-07</td>\n",
       "      <td>95.45 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Roma</td>\n",
       "      <td>Anneli</td>\n",
       "      <td>rehellinen (honest)</td>\n",
       "      <td>1.354460e-05</td>\n",
       "      <td>6.334038e-07</td>\n",
       "      <td>95.32 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Russian</td>\n",
       "      <td>Nikolai</td>\n",
       "      <td>ahkera (diligent)</td>\n",
       "      <td>4.388241e-06</td>\n",
       "      <td>2.205720e-07</td>\n",
       "      <td>94.97 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Finnish-Swedish</td>\n",
       "      <td>Laura</td>\n",
       "      <td>sairas (sick)</td>\n",
       "      <td>6.494232e-04</td>\n",
       "      <td>3.499567e-05</td>\n",
       "      <td>94.61 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Sami</td>\n",
       "      <td>man</td>\n",
       "      <td>fiksu (smart)</td>\n",
       "      <td>8.352658e-07</td>\n",
       "      <td>5.195130e-08</td>\n",
       "      <td>93.78 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Roma</td>\n",
       "      <td>Anneli</td>\n",
       "      <td>ahkera (diligent)</td>\n",
       "      <td>6.967813e-06</td>\n",
       "      <td>4.671830e-07</td>\n",
       "      <td>93.30 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Sami</td>\n",
       "      <td>Hugo</td>\n",
       "      <td>iloinen (cheerful)</td>\n",
       "      <td>7.443557e-06</td>\n",
       "      <td>5.028585e-07</td>\n",
       "      <td>93.24 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ethnicity   Entity          Biased term  Original prob.  \\\n",
       "232          Russian    Irina    ahkera (diligent)    2.922330e-06   \n",
       "199             Sami     Hugo       vaalea (light)    6.740463e-04   \n",
       "95              Roma    Veijo    ahkera (diligent)    4.512612e-06   \n",
       "98              Roma    Veijo  rehellinen (honest)    1.040887e-05   \n",
       "88              Roma   Anneli  rehellinen (honest)    1.354460e-05   \n",
       "242          Russian  Nikolai    ahkera (diligent)    4.388241e-06   \n",
       "36   Finnish-Swedish    Laura        sairas (sick)    6.494232e-04   \n",
       "163             Sami      man        fiksu (smart)    8.352658e-07   \n",
       "85              Roma   Anneli    ahkera (diligent)    6.967813e-06   \n",
       "191             Sami     Hugo   iloinen (cheerful)    7.443557e-06   \n",
       "\n",
       "         New prob   Change  \n",
       "232  9.866292e-08  96.62 %  \n",
       "199  2.470922e-05  96.33 %  \n",
       "95   1.846974e-07  95.91 %  \n",
       "98   4.740756e-07  95.45 %  \n",
       "88   6.334038e-07  95.32 %  \n",
       "242  2.205720e-07  94.97 %  \n",
       "36   3.499567e-05  94.61 %  \n",
       "163  5.195130e-08  93.78 %  \n",
       "85   4.671830e-07  93.30 %  \n",
       "191  5.028585e-07  93.24 %  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top n changes - biased terms\n",
    "visualize.get_top_n_changes(dro_s_raw, file_name='dro_s_top_10.tex', no_unk=True)\n",
    "visualize.get_top_n_changes(dro_l_raw, file_name='dro_l_top_10.tex', no_unk=True)\n",
    "\n",
    "# get top n changes - antonyms\n",
    "temp = visualize.get_sdb_df(dro_s_ant, c.context_t_i, tokenizer)\n",
    "temp2 = visualize.get_sdb_df(dro_l_ant, c.context_long_t_i, tokenizer)\n",
    "visualize.get_top_n_changes(temp, file_name='dro_s_ant_top_10.tex', no_unk=True)\n",
    "visualize.get_top_n_changes(temp2, file_name='dro_l_ant_top_10.tex', no_unk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8173c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:331: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(res.to_latex(index=False))#TODO, float_format=\"%.5f\"))\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:331: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(res.to_latex(index=False))#TODO, float_format=\"%.5f\"))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Original prob.</th>\n",
       "      <th>New prob</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finnish-Swedish</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>93.26 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sami</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>88.30 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>87.44 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roma</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>67.52 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Somali</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>50.14 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ethnicity  Original prob.  New prob   Change\n",
       "0  Finnish-Swedish        0.000368  0.000025  93.26 %\n",
       "1             Sami        0.000296  0.000035  88.30 %\n",
       "2          Russian        0.000145  0.000018  87.44 %\n",
       "3             Roma        0.000112  0.000036  67.52 %\n",
       "4           Somali        0.000017  0.000008  50.14 %"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize.get_sdb_means(dro_s_raw, 'dro_short_means.tex')\n",
    "visualize.get_sdb_means(dro_l_raw, 'dro_long_means.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1834fc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:331: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(res.to_latex(index=False))#TODO, float_format=\"%.5f\"))\n",
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:331: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(res.to_latex(index=False))#TODO, float_format=\"%.5f\"))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Original prob.</th>\n",
       "      <th>New prob</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finnish-Swedish</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>93.26 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sami</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>88.30 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russian</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>87.44 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roma</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>67.52 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Somali</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>50.14 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ethnicity  Original prob.  New prob   Change\n",
       "0  Finnish-Swedish        0.000368  0.000025  93.26 %\n",
       "1             Sami        0.000296  0.000035  88.30 %\n",
       "2          Russian        0.000145  0.000018  87.44 %\n",
       "3             Roma        0.000112  0.000036  67.52 %\n",
       "4           Somali        0.000017  0.000008  50.14 %"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dro_s_ant_comb = visualize.get_sdb_ant_df(dro_s_raw, dro_s_ant_raw)\n",
    "dro_l_ant_comb = visualize.get_sdb_ant_df(dro_l_raw, dro_l_ant_raw)\n",
    "\n",
    "visualize.get_sdb_means(dro_s_ant_comb, 'dro_short_means.tex')\n",
    "visualize.get_sdb_means(dro_l_ant_comb, 'dro_long_means.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a0a461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussuvmi@GU.GU.SE/thesis/visualize.py:41: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  file.write(result.to_latex(index=index, longtable=longtable, float_format=float_format))\n"
     ]
    }
   ],
   "source": [
    "# Comparing top k words\n",
    "dro_top_k_s = visualize.get_top_k_df(dro_s_debiased, dro_tokenizer, c.context_t_i, \"dro\", \"s\")\n",
    "dro_top_k_l = visualize.get_top_k_df(dro_l_debiased, dro_tokenizer, c.context_long_t_i, \"dro\", \"l\")\n",
    "\n",
    "\n",
    "top_k_s = visualize.combine_top_k(sdb_top_k_s, dro_top_k_s)\n",
    "top_k_l = visualize.combine_top_k(sdb_top_k_l, dro_top_k_l)\n",
    "\n",
    "# save interesting tables - not all of the tables contain very valuable/new observations afai can tell\n",
    "top_som_s = top_k_s[top_k_s[\"Ethnicity\"] == \"Somali\"].drop([\"Ethnicity\"], axis=1)\n",
    "top_rom_s = top_k_s[top_k_s[\"Ethnicity\"] == \"Roma\"].drop([\"Ethnicity\"], axis=1) # why for roma overweight is not considered biased but for other groups it is?\n",
    "top_som_l = top_k_l[top_k_s[\"Ethnicity\"] == \"Somali\"].drop([\"Ethnicity\"], axis=1)\n",
    "top_rom_l = top_k_l[top_k_s[\"Ethnicity\"] == \"Roma\"].drop([\"Ethnicity\"], axis=1) # same here with overweight\n",
    "top_fswe_l = top_k_l[top_k_s[\"Ethnicity\"] == \"Finnish-Swedish\"].drop([\"Ethnicity\"], axis=1)\n",
    "visualize.save(\"Results/tables/top_som_s.tex\", top_som_s, index=False, longtable=True, float_format=\"%.3f\")\n",
    "visualize.save(\"Results/tables/top_rom_s.tex\", top_rom_s, index=False, longtable=True, float_format=\"%.3f\")\n",
    "visualize.save(\"Results/tables/top_som_l.tex\", top_som_l, index=False, longtable=True, float_format=\"%.3f\")\n",
    "visualize.save(\"Results/tables/top_rom_l.tex\", top_rom_l, index=False, longtable=True, float_format=\"%.3f\")\n",
    "visualize.save(\"Results/tables/top_fswe_l.tex\", top_fswe_l, index=False, longtable=True, float_format=\"%.3f\")\n",
    "# TODO add others to appendix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9724648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do detect bias between entities in ethnic group? I think I have it somewhere???????????????? in scores notebook\n",
    "# TODO add control group? Or thats only for previous part of the work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "875f71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO should I do association scores as well? -> add means and how much they went down to wrap things up nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46edb7",
   "metadata": {},
   "source": [
    "## Association scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2a49a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import self_debias as sdb\n",
    "\n",
    "short = data.get_context_sentences(c.context, c.context_t_i, c.context_a_i)\n",
    "long = data.get_context_sentences(c.context_long, c.context_long_t_i, c.context_long_a_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec63de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dro_model, dro_tokenizer = score.get_model('test-mlm/')\n",
    "dro_s_asc = score.process_scores(dro_model, tokenizer, short)\n",
    "dro_l_asc = score.process_scores(dro_model, tokenizer, long)\n",
    "\n",
    "s_dro_asc_df = visualize.get_df(dro_s_asc[0], dro_s_asc[1], dro_tokenizer)\n",
    "visualize.get_nat_means(s_dro_asc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d5ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_dro_asc_df = visualize.get_df(dro_l_asc[0], dro_l_asc[1], dro_tokenizer)\n",
    "visualize.get_nat_means(l_dro_asc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdb \n",
    "model, tokenizer = score.get_model()\n",
    "\n",
    "# save target and prior probs\n",
    "sdb.save_sdb_association_scores(model, tokenizer, short, pref=\"s_\")\n",
    "sdb.save_sdb_association_scores(model, tokenizer, long, pref=\"l_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8224e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_sdb_target_probs = load(\"s_sdb_target_probs.json\")\n",
    "s_sdb_prior_probs = load(\"s_sdb_prior_probs.json\")\n",
    "mask = \"[MASK]\"\n",
    "import numpy as np\n",
    "# TODO name sentence in priors is does not have CLS and SEP :--)\n",
    "# TODO something wrong bc the unchanged scores are different from before...\n",
    "for k in s_sdb_target_probs:\n",
    "    prior_sents = [sent[0][:7] for sent in s_sdb_prior_probs[k].values()] # TODO only worky for short sentence rn\n",
    "    for i in s_sdb_target_probs[k]:\n",
    "        t_sent = s_sdb_target_probs[k][i][0]\n",
    "        p_sent = s_sdb_prior_probs[k][str(prior_sents.index(t_sent[:7]))]\n",
    "        # TODO get the correct target probability\n",
    "        # TODO get prior probability\n",
    "        # target is ethnicity if mask is followed by ##entity, otherwise use names\n",
    "        masked_i = t_sent.index(mask)\n",
    "        if \"##\" in t_sent[masked_i+1]:# == \"##nainen\" or t_sent[masked_i+1] == \"##mies\" or t_sent[masked_i+1] == \"##henkilö\":\n",
    "            target = s_sdb_target_probs[k][i][1]\n",
    "            print(t_sent)\n",
    "            print(target)\n",
    "            print(p_sent[1])\n",
    "            target_p = target[2]\n",
    "            prior_p = p_sent[1][2]\n",
    "            association_score = np.log(float(target_p / prior_p))\n",
    "            print(association_score)\n",
    "            # (score, ethnicity, biased_term, entity)\n",
    "        else:\n",
    "            target_f = s_sdb_target_probs[k][i][2] \n",
    "            target_m = s_sdb_target_probs[k][i][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tempp = {'roma': s['roma']}\n",
    "#tempp2 = {'roma': s2['roma']}\n",
    "#tempp['roma']['sents'] = tempp['roma']['sents'][:5]\n",
    "#tempp['roma']['terms'] = ['romani']\n",
    "#tempp2['roma']['sents'] = tempp2['roma']['sents'][:1]\n",
    "#tempp2['roma']['terms'] = ['romani']\n",
    "\n",
    "#target_probs = sdb.get_bert_and_new_probs(tempp, model, tokenizer, tokenize=False)\n",
    "#prior_probs = sdb.get_bert_and_new_probs(tempp2, model, tokenizer, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e121f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#for k in target_probs:\n",
    "#    for k2 in target_probs[k]:\n",
    "#        target_p = target_probs[k][k2][1][2]\n",
    "#        prior_p = prior_probs[k][k2][1][2]\n",
    "#        print(target_p, prior_p)\n",
    "#        print(np.log(float(target_p/prior_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee58a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceea7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import score\n",
    "#model, tokenizer = score.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#score.get_sentence_probabilities(model, tokenizer, \"Tutkimusten mukaan tyypillinen romaninainen on usein työtön.\", 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd6e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.log(0.0111 / 0.0029)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feee96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25dea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
